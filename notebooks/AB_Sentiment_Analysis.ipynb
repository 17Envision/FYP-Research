{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b93b8ce1-9ccb-43ce-8fa8-a063323225ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langid.langid import LanguageIdentifier, model\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caf3cbce-91b6-4b7e-a5df-8dbf5609ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\UOM\\\\L4S1\\\\Research\\\\Implementation\\\\FYP-Research\\\\notebooks'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d5cab92-154a-4c91-9f30-03f18beaf15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Comment Id              User Id        Unique Id  \\\n",
      "0  7314765604681810706  6876105532748530693  20dark_hunter00   \n",
      "1  7314907545561907970  6982416764534309894        kavi___09   \n",
      "2  7314935455757484801  7187578911432705029    romeshjanaka7   \n",
      "3  7314731362967257857  6698376036462527493            u2me_   \n",
      "4  7314854241218118408  6854570108179678214    asunthapathum   \n",
      "\n",
      "           Nickname                                             Avatar  \\\n",
      "0       Dark Hunter  https://p16-sign-useast2a.tiktokcdn.com/tos-us...   \n",
      "1  Kavindu tharusha  https://p16-sign-sg.tiktokcdn.com/aweme/100x10...   \n",
      "2     romeshjanaka7  https://p16-sign-useast2a.tiktokcdn.com/tos-us...   \n",
      "3              U2me  https://p16-sign-va.tiktokcdn.com/musically-ma...   \n",
      "4    Asuntha Pathum  https://p16-sign-sg.tiktokcdn.com/aweme/100x10...   \n",
      "\n",
      "                                  User URL  Reply Comment Id  \\\n",
      "0  https://www.tiktok.com/@20dark_hunter00                 0   \n",
      "1        https://www.tiktok.com/@kavi___09                 0   \n",
      "2    https://www.tiktok.com/@romeshjanaka7                 0   \n",
      "3            https://www.tiktok.com/@u2me_                 0   \n",
      "4    https://www.tiktok.com/@asunthapathum                 0   \n",
      "\n",
      "                                             Comment  Digg Count  Reply Count  \\\n",
      "0  ‡∂á‡∂∫‡∑í display issues ‡∂ú‡∑ê‡∂± ‡∂ö‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö ‡∂±‡∑ê‡∂≠‡∑ä‡∂≠‡∑ö S ser...          22         46.0   \n",
      "1                        Update ‡∂ö‡∂ª‡∑è‡∂ß ‡∂¥‡∑É‡∑ä‡∑É‡∑ö ‡∂â‡∂ª‡∑í ‡∂∫‡∂∫‡∑í‡∂ØüëÄ          16         12.0   \n",
      "2                              ‡∂¥‡∂≠ ‡∂Ω‡∂∫‡∑í‡∂±‡∑ä ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ú‡∑í‡∂∫‡∑è‡∂∏ üòÇ          10          9.0   \n",
      "3                   üòÇ ‡∑Ä‡∑ê‡∂©‡∂ö‡∑ä ‡∑Ä‡∑ô‡∂±‡∑ä ‡∂±‡∑ë ‡∂∂‡∂±‡∑ä ‡∂ú‡∂±‡∑ä‡∂± ‡∑Ä‡∑ô‡∂±‡∑ä ‡∂±‡∑ë          28          2.0   \n",
      "4                                 gerrn line enwne üòÇ           5          4.0   \n",
      "\n",
      "   Is Author Digged  Author Pin Language          Create Time  \\\n",
      "0              True         0.0       si  2023-12-21 01:16:57   \n",
      "1              True         0.0       si  2023-12-21 10:27:32   \n",
      "2              True         0.0       si  2023-12-21 12:15:55   \n",
      "3              True         0.0       si  2023-12-20 23:03:58   \n",
      "4              True         0.0       en  2023-12-21 07:00:55   \n",
      "\n",
      "                                           Video URL             Video Id  \n",
      "0  https://www.tiktok.com/@tech_with_wicky/video/...  7314721689806376197  \n",
      "1  https://www.tiktok.com/@tech_with_wicky/video/...  7314721689806376197  \n",
      "2  https://www.tiktok.com/@tech_with_wicky/video/...  7314721689806376197  \n",
      "3  https://www.tiktok.com/@tech_with_wicky/video/...  7314721689806376197  \n",
      "4  https://www.tiktok.com/@tech_with_wicky/video/...  7314721689806376197  \n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "# Detect encoding\n",
    "with open(\"../data/dataset.xlsx\", 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    encoding = result['encoding']\n",
    "\n",
    "# Read the file with the detected encoding\n",
    "df = pd.read_excel(\"../data/dataset.xlsx\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c24516b6-8ef3-431e-ae14-80bca511c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Comment Language\n",
      "0   ‡∂á‡∂∫‡∑í display issues ‡∂ú‡∑ê‡∂± ‡∂ö‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö ‡∂±‡∑ê‡∂≠‡∑ä‡∂≠‡∑ö S ser...       si\n",
      "1                         Update ‡∂ö‡∂ª‡∑è‡∂ß ‡∂¥‡∑É‡∑ä‡∑É‡∑ö ‡∂â‡∂ª‡∑í ‡∂∫‡∂∫‡∑í‡∂ØüëÄ       si\n",
      "2                               ‡∂¥‡∂≠ ‡∂Ω‡∂∫‡∑í‡∂±‡∑ä ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ú‡∑í‡∂∫‡∑è‡∂∏ üòÇ       si\n",
      "3                    üòÇ ‡∑Ä‡∑ê‡∂©‡∂ö‡∑ä ‡∑Ä‡∑ô‡∂±‡∑ä ‡∂±‡∑ë ‡∂∂‡∂±‡∑ä ‡∂ú‡∂±‡∑ä‡∂± ‡∑Ä‡∑ô‡∂±‡∑ä ‡∂±‡∑ë       si\n",
      "5                          ‡∂á‡∂¥‡∂Ω‡∑ä ‡∑Ä‡∂Ω‡∂ß‡∂≠‡∑ä ‡∂ö‡∑ô‡∂Ω‡∑í‡∂∫ ‡∂ë‡∑Ñ‡∑ô‡∂±‡∂∏‡∑ä üòÇüòÇ       si\n",
      "6                   ‡∂Ö‡∂ª ‡∑Ä‡∑ô‡∂±‡∑É‡∑ä ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂ö‡∑ù‡∂Ω‡∑ä ‡∂ú‡∂±‡∑ä‡∂± ‡∂ë‡∂ö ‡∑É‡∑ô‡∂ß‡∑ä ‡∂á       si\n",
      "7                                   ‡∂ö‡∑í‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑í‡∂≠‡∂ª ‡∑Ä‡∑ö‡∑Ä‡∑í‡∂Ø?       si\n",
      "11                            Samsumg ‡∂≠‡∂∏‡∑è ‡∂ë‡∂Ø‡∂≠‡∑ä ‡∂Ö‡∂Ø‡∂≠‡∑äüñ§üî•       si\n",
      "12                        pixel ‡∑Ä‡∂Ω‡∂ß‡∂≠‡∑ä Review ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ï‡∂±‡∑ô       si\n",
      "15                                  ‡∂ë‡∑Ñ‡∑ô‡∂±‡∂∏‡∑ä ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ú‡∂∏‡∑î üôÇ       si\n",
      "16                                      ‡∑É‡∑ê‡∂∏‡∑ä‡∑É‡∑î‡∂±‡∑ä‡∂ú‡∑ä ü§ç‚ú®       si\n",
      "18          ‡∂ß‡∂∫‡∑í‡∂ß‡∑ö‡∂±‡∑í‡∂∫‡∂∏‡∑ä ‡∂ö‡∂±‡∑ä‡∂±‡∂Ø ‡∂ö‡∑í‡∂∫‡∂¥‡∑î ‡∑É‡∑ê‡∂∏‡∑ä‡∑É‡∂±‡∑ä ‡∑Ü‡∑ë‡∂±‡∑ä ‡∂Ω‡∑è..üòÖ       si\n",
      "19                         s23 eka ‡∂∏‡∑ö ‡∂∏‡∑è‡∑É‡∑ô ‡∂ú‡∂≠‡∑ä‡∂≠ ‡∂∏‡∂∏ ü•∫üòì       si\n",
      "20                                              üòÇ ‡∂â‡∂∫‡∑è       si\n",
      "22                               ‡∑Ñ‡∑ú‡∂Ø‡∂∏ ‡∂ë‡∂ö ‡∂Ω‡∑ù‡∂ö‡∑ô ‡∂Ø‡∑ê‡∂±‡∑ä‡∂±‡∂∏‡∑ñ       si\n",
      "23                    ‡∂≠‡∑è‡∂∏ m02 ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂¥‡∑è‡∑Ä‡∑í‡∂†‡∑ä‡∂†‡∑í ‡∂ö‡∂ª‡∂± ‡∂∏‡∂∏ üôÇüëç       si\n",
      "24                  Mata ahuneme ‡∂í ‡∂á‡∂∫‡∑í kiyala maüòÖüòÖüòÖüòÖüòÖ       si\n",
      "25  Apple ‡∑Ä‡∂Ω ‡∂ß‡∂∫‡∑í‡∂ß‡∑ö‡∂±‡∑í‡∂∫‡∂∏‡∑ä ‡∑Ä‡∂Ω‡∂ß ‡∂∂‡∑ê‡∂± ‡∂∂‡∑ê‡∂± ‡∑Ñ‡∑í‡∂ß‡∂¥‡∑î ‡∂ã‡∂±‡∑ä ‡∂ß‡∂∫‡∑í‡∂ß...       si\n",
      "26  ‡∂Ω‡∂Ç‡∂ö‡∑è‡∑Ä‡∑ö ‡∂Ö‡∂¥‡∑í‡∂ß ‡∂∏‡∑ú‡∂ö‡∂ö‡∑ä ‡∂Ü‡∑Ä‡∂≠‡∑ä ‡∂ú‡∂±‡∑ä‡∂± ‡∑Ä‡∑ô‡∂±‡∑ä‡∂±‡∑ë 25000‡∂ß ‡∂Ü‡∂¥‡∑î ...       si\n",
      "29  @Nirosh Madushan ‡∂ß‡∑ô‡∂Ω‡∑í‡∑É‡∑ä‡∂ö‡∑ú‡∂¥‡∑ä ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ë‡∂±‡∑ä‡∂±‡∑ê‡∂Ω‡∑î ‡∂∂‡∂±‡∑ä 1...       si\n",
      "45                       ‡∂¥‡∂Ω‡∂≠‡∑î‡∂ª‡∑î ‡∑Ä‡∂Ω‡∂ß ‡∑Ä‡∂©‡∑è ‡∂±‡∂∏‡∑ä ‡∑Ñ‡∑ú‡∂Ø‡∂∫‡∑í üíÄ‚úåÔ∏è       si\n",
      "47  s23 294 dan $$ 257 ‡∑Ä‡∑ê‡∂© ‡∑É‡∂¥‡∑í‡∂ª‡∑í ipone ‡∂ö‡∑ê‡∂Ω‡∑ö ‡∂ë‡∂≠‡∂ª‡∂±‡∑ä ...       si\n",
      "48  ‡∂∂‡∑ú‡∂ª‡∑î‡∑Ä‡∂ß green line ‡∂ú‡∑ê‡∂± ‡∂ö‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂ë‡∂¥‡∑è ‡∑Ñ‡∑ê‡∂∏ ‡∂ë‡∂ö‡∂ß‡∂∏ ‡∂ë...       si\n",
      "49  green lineüòÇ\\n‡∂ß‡∂∫‡∑í‡∂ß‡∑ö‡∂±‡∑í‡∂∫‡∂∏‡∑ä ‡∑Ä‡∂Ω‡∂ß ‡∂∂‡∑ê‡∂±‡∑ä‡∂± ‡∂ã‡∂±‡∑ä ‡∂∏‡∑Ñ‡∑í‡∂±‡∑ä‡∂Ø ‡∂ë...       si\n",
      "50                              ‡∂á‡∂¥‡∂Ω‡∑ä ‡∂ö‡∑ú‡∑Ñ‡∑ô‡∂Ø ‡∑Ñ‡∑î‡∂≠‡∑ä‡∂≠‡∑ù ‡∑Ñ‡∑ú‡∂≥       si\n",
      "53  ‡∂ª‡∑ê‡∂Ω‡∑ä‡∂Ω‡∂ß ‡∂±‡∂∏‡∑ä ‡∂±‡∑ô‡∂∏‡∑ö ‡∑Ñ‡∑ê‡∂∂‡∑ê‡∂∫‡∑í ‡∂Ö‡∑Ä‡∑î‡∂ª‡∑î‡∂Ø‡∑î 3 4 k ‡∂ã‡∂±‡∂≠‡∑ä spee...       si\n",
      "54  ‡∂∏‡∂∏ apple samsung ‡∑Ä‡∂Ω flagship phone ‡∂¥‡∑è‡∑Ä‡∑í‡∂†‡∑ä‡∂†‡∑í ‡∂ö‡∂ª...       si\n",
      "64  green line ‡∑Ä‡∑í‡∂≠‡∂ª‡∂∫‡∑í ‡∂±‡∑ö. iphone ‡∑Ä‡∂ú‡∑ö ‡∂∏‡∑î‡∑Ö‡∑î screen ‡∂ë...       si\n",
      "69                         ‡∂≠‡∑è‡∂∏ ‡∂±‡∑ë ‡∂≠‡∑Ä ‡∂Ö‡∑Ä‡∑î‡∂ª‡∑î‡∂Ø‡∑ä‡∂Ø‡∂ö‡∑í‡∂±‡∑ä ‡∂ë‡∂∫‡∑í       si\n",
      "91  ane hutta ‡∂≠‡∂∏‡∂∫‡∑í ‡∂Ö‡∑Ä‡∑î‡∂ª‡∑î‡∂Ø‡∑î ganak s serios use ‡∂ö‡∂ª‡∂±‡∑ä...       si\n",
      "92  ‡∂∏‡∑è‡∂≠‡∑ä ‡∂Ø‡∑ê‡∂±‡∑ä ‡∂Ö‡∑Ä‡∑î‡∂ª‡∑î‡∂Ø‡∑î ‡∂ú‡∑è‡∂±‡∂ö‡∑ä ‡∂≠‡∑í‡∑É‡∑ä‡∑É‡∑ö Samsung ‡∂∫‡∑î‡∑É‡∑ä ‡∂ö‡∂ª...       si\n",
      "93  ‡∂ë‡∂±‡∑ä‡∂± ‡∂ö‡∂Ω‡∑í‡∂∏‡∑ä ‡∂≠‡∑ù ‡∂ö‡∑ú‡∑Ñ‡∑ú‡∂∏‡∂Ø ‡∂∂‡∂Ç ‡∂ö‡∑í‡∂∫‡∂±‡∑ä‡∂±‡∑ö üòÇüíî ‡∂Ü‡∑Ä‡∂∏ ‡∂ö‡∑í‡∂∫‡∂¥‡∂±‡∑ä ...       si\n",
      "96                                 ‡∂Ö‡∂¥‡∑í‡∂ß‡∂≠‡∑ä ‡∂ë‡∂±‡∑ä‡∂± ‡∂ë‡∂¥‡∑ê ?üíÄ       si\n",
      "97  wadak na ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è . chaina use karana un ge padi ...       si\n",
      "98  ‡∂ö‡∑ù ‡∂∂‡∂±‡∑ä ‡∂â‡∂≠‡∑í‡∂±‡∑ä ‡∂Ü‡∑Ä‡∑ô ‡∂±‡∑ë‡∂±‡∑ô. S9 ‡∂ë‡∂ö‡∂ö‡∑î‡∂≠‡∑ä ‡∂≠‡∑í‡∂∫‡∑ö ‡∂≠‡∑è‡∂∏ ‡∂â‡∂ª‡∂ö‡∑ä...       si\n"
     ]
    }
   ],
   "source": [
    "import langid\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' with a 'Comment' column\n",
    "# ...\n",
    "\n",
    "# Function to identify the language of a comment\n",
    "def identify_language(comment):\n",
    "    lang, _ = langid.classify(comment)\n",
    "    return lang\n",
    "\n",
    "# Apply the language identification function to the \"Comment\" column\n",
    "df['Language'] = df['Comment'].apply(identify_language)\n",
    "\n",
    "# Filter only Sinhala comments\n",
    "sinhala_comments_df = df[df['Language'] == 'si']\n",
    "\n",
    "# Display the Sinhala comments DataFrame\n",
    "print(sinhala_comments_df[['Comment', 'Language']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "715e87f9-4908-4abe-b499-bdcb5f1a1410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd34ee-f143-43ea-b8d4-5568a744de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e15928-ead7-448b-b84d-ed1e1c3e4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_english_words(column):\n",
    "    # Define a regular expression pattern to match English words\n",
    "    english_word_pattern = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "\n",
    "    # Use sub() to replace matched English words with an empty string\n",
    "    cleaned_column = column.apply(lambda x: re.sub(english_word_pattern, '', x))\n",
    "\n",
    "    return cleaned_column\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named 'sinhala_comments_df'\n",
    "# sinhala_comments_df[['Comment', 'Language']] will give you the desired columns\n",
    "columns_to_clean = sinhala_comments_df[['Comment', 'Language']]\n",
    "cleaned_columns = columns_to_clean.apply(remove_english_words)\n",
    "\n",
    "# Display the original and cleaned columns\n",
    "print(\"\\nCleaned Columns:\")\n",
    "print(cleaned_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447e598-e783-42e0-b34d-8b90f4b39e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
